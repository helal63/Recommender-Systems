{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "movielens",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfI9GqZoSI29",
        "colab_type": "text"
      },
      "source": [
        "The objective of this notebook (project) is to test multiple recommendation systems for the movielens dataset. Here are the different models that we have tried to implement\n",
        "\n",
        "1- **Matrix Factorization techniques with SGD learning (https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf)**\n",
        "- Can't use SVD because the matrix is sparse.\n",
        "- We replicate this behaviour using deep learning.\n",
        "- Add bias terms & regularization\n",
        "\n",
        "2- Wide & Deep for recommender systems: We have tried to implement the following paper https://arxiv.org/pdf/1606.07792.pdf from Google, however, as the paper states, the wide part is built using binary cross-product features. Those features would need to manually be built and would explode the amount of neurons in the wide part.\n",
        "More information on feature crosses: https://datascience.stackexchange.com/questions/57435/how-is-the-cross-product-transformation-defined-for-binary-features?newreg=2093b549d07e43db92e28eccecb6a73b\n",
        "\n",
        "3- Neural Collaborative Filtering\n",
        "\n",
        "Dataset used: http://files.grouplens.org/datasets/movielens/ml-1m-README.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDRzv7UupvPP",
        "colab_type": "code",
        "outputId": "3d171728-1b42-4522-ba17-99a8c5d64160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/skorch-dev/skorch.git\n",
        "!cd skorch && python setup.py install"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'skorch' already exists and is not an empty directory.\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing skorch.egg-info/PKG-INFO\n",
            "writing dependency_links to skorch.egg-info/dependency_links.txt\n",
            "writing requirements to skorch.egg-info/requires.txt\n",
            "writing top-level names to skorch.egg-info/top_level.txt\n",
            "reading manifest template 'MANIFEST.in'\n",
            "writing manifest file 'skorch.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/skorch\n",
            "copying build/lib/skorch/exceptions.py -> build/bdist.linux-x86_64/egg/skorch\n",
            "copying build/lib/skorch/dataset.py -> build/bdist.linux-x86_64/egg/skorch\n",
            "creating build/bdist.linux-x86_64/egg/skorch/callbacks\n",
            "copying build/lib/skorch/callbacks/base.py -> build/bdist.linux-x86_64/egg/skorch/callbacks\n",
            "copying build/lib/skorch/callbacks/scoring.py -> build/bdist.linux-x86_64/egg/skorch/callbacks\n",
            "copying build/lib/skorch/callbacks/lr_scheduler.py -> build/bdist.linux-x86_64/egg/skorch/callbacks\n",
            "copying build/lib/skorch/callbacks/regularization.py -> build/bdist.linux-x86_64/egg/skorch/callbacks\n",
            "copying build/lib/skorch/callbacks/__init__.py -> build/bdist.linux-x86_64/egg/skorch/callbacks\n",
            "copying build/lib/skorch/callbacks/logging.py -> build/bdist.linux-x86_64/egg/skorch/callbacks\n",
            "copying build/lib/skorch/callbacks/training.py -> build/bdist.linux-x86_64/egg/skorch/callbacks\n",
            "copying build/lib/skorch/regressor.py -> build/bdist.linux-x86_64/egg/skorch\n",
            "creating build/bdist.linux-x86_64/egg/skorch/tests\n",
            "copying build/lib/skorch/tests/test_utils.py -> build/bdist.linux-x86_64/egg/skorch/tests\n",
            "copying build/lib/skorch/tests/optimizer_cuda.pt -> build/bdist.linux-x86_64/egg/skorch/tests\n",
            "copying build/lib/skorch/tests/test_regressor.py -> build/bdist.linux-x86_64/egg/skorch/tests\n",
            "creating build/bdist.linux-x86_64/egg/skorch/tests/callbacks\n",
            "copying build/lib/skorch/tests/callbacks/test_training.py -> build/bdist.linux-x86_64/egg/skorch/tests/callbacks\n",
            "copying build/lib/skorch/tests/callbacks/test_lr_scheduler.py -> build/bdist.linux-x86_64/egg/skorch/tests/callbacks\n",
            "copying build/lib/skorch/tests/callbacks/test_all.py -> build/bdist.linux-x86_64/egg/skorch/tests/callbacks\n",
            "copying build/lib/skorch/tests/callbacks/test_logging.py -> build/bdist.linux-x86_64/egg/skorch/tests/callbacks\n",
            "copying build/lib/skorch/tests/callbacks/test_regularization.py -> build/bdist.linux-x86_64/egg/skorch/tests/callbacks\n",
            "copying build/lib/skorch/tests/callbacks/test_scoring.py -> build/bdist.linux-x86_64/egg/skorch/tests/callbacks\n",
            "copying build/lib/skorch/tests/test_toy.py -> build/bdist.linux-x86_64/egg/skorch/tests\n",
            "copying build/lib/skorch/tests/test_classifier.py -> build/bdist.linux-x86_64/egg/skorch/tests\n",
            "copying build/lib/skorch/tests/test_helper.py -> build/bdist.linux-x86_64/egg/skorch/tests\n",
            "copying build/lib/skorch/tests/test_cli.py -> build/bdist.linux-x86_64/egg/skorch/tests\n",
            "copying build/lib/skorch/tests/__init__.py -> build/bdist.linux-x86_64/egg/skorch/tests\n",
            "copying build/lib/skorch/tests/test_history.py -> build/bdist.linux-x86_64/egg/skorch/tests\n",
            "copying build/lib/skorch/tests/net_cuda.pt -> build/bdist.linux-x86_64/egg/skorch/tests\n",
            "copying build/lib/skorch/tests/model_0.5.0.pkl -> build/bdist.linux-x86_64/egg/skorch/tests\n",
            "copying build/lib/skorch/tests/test_setter.py -> build/bdist.linux-x86_64/egg/skorch/tests\n",
            "copying build/lib/skorch/tests/test_net.py -> build/bdist.linux-x86_64/egg/skorch/tests\n",
            "copying build/lib/skorch/tests/conftest.py -> build/bdist.linux-x86_64/egg/skorch/tests\n",
            "copying build/lib/skorch/tests/test_dataset.py -> build/bdist.linux-x86_64/egg/skorch/tests\n",
            "copying build/lib/skorch/tests/net_cuda.pkl -> build/bdist.linux-x86_64/egg/skorch/tests\n",
            "copying build/lib/skorch/setter.py -> build/bdist.linux-x86_64/egg/skorch\n",
            "copying build/lib/skorch/__init__.py -> build/bdist.linux-x86_64/egg/skorch\n",
            "copying build/lib/skorch/history.py -> build/bdist.linux-x86_64/egg/skorch\n",
            "copying build/lib/skorch/utils.py -> build/bdist.linux-x86_64/egg/skorch\n",
            "copying build/lib/skorch/classifier.py -> build/bdist.linux-x86_64/egg/skorch\n",
            "copying build/lib/skorch/toy.py -> build/bdist.linux-x86_64/egg/skorch\n",
            "copying build/lib/skorch/net.py -> build/bdist.linux-x86_64/egg/skorch\n",
            "copying build/lib/skorch/helper.py -> build/bdist.linux-x86_64/egg/skorch\n",
            "copying build/lib/skorch/cli.py -> build/bdist.linux-x86_64/egg/skorch\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/exceptions.py to exceptions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/dataset.py to dataset.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/callbacks/base.py to base.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/callbacks/scoring.py to scoring.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/callbacks/lr_scheduler.py to lr_scheduler.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/callbacks/regularization.py to regularization.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/callbacks/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/callbacks/logging.py to logging.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/callbacks/training.py to training.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/regressor.py to regressor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/tests/test_utils.py to test_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/tests/test_regressor.py to test_regressor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/tests/callbacks/test_training.py to test_training.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/tests/callbacks/test_lr_scheduler.py to test_lr_scheduler.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/tests/callbacks/test_all.py to test_all.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/tests/callbacks/test_logging.py to test_logging.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/tests/callbacks/test_regularization.py to test_regularization.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/tests/callbacks/test_scoring.py to test_scoring.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/tests/test_toy.py to test_toy.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/tests/test_classifier.py to test_classifier.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/tests/test_helper.py to test_helper.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/tests/test_cli.py to test_cli.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/tests/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/tests/test_history.py to test_history.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/tests/test_setter.py to test_setter.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/tests/test_net.py to test_net.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/tests/conftest.py to conftest.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/tests/test_dataset.py to test_dataset.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/setter.py to setter.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/history.py to history.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/classifier.py to classifier.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/toy.py to toy.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/net.py to net.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/helper.py to helper.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/skorch/cli.py to cli.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying skorch.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying skorch.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying skorch.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying skorch.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying skorch.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying skorch.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "creating 'dist/skorch-0.6.1.dev0-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing skorch-0.6.1.dev0-py3.6.egg\n",
            "removing '/usr/local/lib/python3.6/dist-packages/skorch-0.6.1.dev0-py3.6.egg' (and everything under it)\n",
            "creating /usr/local/lib/python3.6/dist-packages/skorch-0.6.1.dev0-py3.6.egg\n",
            "Extracting skorch-0.6.1.dev0-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "skorch 0.6.1.dev0 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/skorch-0.6.1.dev0-py3.6.egg\n",
            "Processing dependencies for skorch==0.6.1.dev0\n",
            "Searching for tqdm==4.28.1\n",
            "Best match: tqdm 4.28.1\n",
            "Adding tqdm 4.28.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tabulate==0.8.3\n",
            "Best match: tabulate 0.8.3\n",
            "Adding tabulate 0.8.3 to easy-install.pth file\n",
            "Installing tabulate script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.3.1\n",
            "Best match: scipy 1.3.1\n",
            "Adding scipy 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scikit-learn==0.21.3\n",
            "Best match: scikit-learn 0.21.3\n",
            "Adding scikit-learn 0.21.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.16.5\n",
            "Best match: numpy 1.16.5\n",
            "Adding numpy 1.16.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for joblib==0.13.2\n",
            "Best match: joblib 0.13.2\n",
            "Adding joblib 0.13.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for skorch==0.6.1.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAL_cX1zzHlL",
        "colab_type": "code",
        "outputId": "7ba79a9b-6cbf-4a95-9834-d98b361e6570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "!pip install tensorboard future pillow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (0.16.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (4.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.15.6)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.16.5)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.7.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.33.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (41.2.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM7d0NnVG2kt",
        "colab_type": "code",
        "outputId": "49015d90-3934-4fcb-d364-752a95ee4c9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "!pip install ipywidgets\n",
        "!jupyter nbextension enable --py widgetsnbextension"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (7.5.1)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (4.4.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (4.3.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets) (4.6.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.1.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (41.2.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (1.0.16)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.7.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.4.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets) (5.2.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.5.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets) (2.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets) (1.12.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets) (4.5.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.10.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (5.6.0)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.5.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (17.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.1.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
            "Enabling notebook extension jupyter-js-widgets/extension...\n",
            "      - Validating: \u001b[32mOK\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQZgn3JNuFXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import patsy\n",
        "import time\n",
        "\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from skorch import NeuralNet\n",
        "from skorch.helper import predefined_split, SliceDataset\n",
        "from skorch.callbacks import BatchScoring, Checkpoint, EarlyStopping, EpochScoring, LRScheduler, TensorBoard, ProgressBar\n",
        "\n",
        "# Install latest Tensorflow build\n",
        "!pip install -q tf-nightly-2.0-preview\n",
        "import tensorflow as tf\n",
        "from tensorflow import summary\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYaQB02n1Md_",
        "colab_type": "code",
        "outputId": "e0fedd2a-edd8-4fa4-c812-18752d9e332b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Torch parameters\n",
        "identifier = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "device = torch.device(identifier)\n",
        "device = 'cpu'\n",
        "print('Using device ', device)\n",
        "\n",
        "print('Using torch version ', torch.__version__)\n",
        "\n",
        "torch.set_printoptions(precision=7)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device  cpu\n",
            "Using torch version  1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9wVhoAfiDwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive2')#, force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvYWqFf2uG9j",
        "colab_type": "code",
        "outputId": "0a6594ad-c7da-407a-ca5a-b34cbbefbc86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
        "!unzip -o ml-1m.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-20 22:36:48--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘ml-1m.zip.10’\n",
            "\n",
            "\rml-1m.zip.10          0%[                    ]       0  --.-KB/s               \rml-1m.zip.10         15%[==>                 ] 891.46K  4.12MB/s               \rml-1m.zip.10        100%[===================>]   5.64M  17.6MB/s    in 0.3s    \n",
            "\n",
            "2019-09-20 22:36:49 (17.6 MB/s) - ‘ml-1m.zip.10’ saved [5917549/5917549]\n",
            "\n",
            "Archive:  ml-1m.zip\n",
            "  inflating: ml-1m/movies.dat        \n",
            "  inflating: ml-1m/ratings.dat       \n",
            "  inflating: ml-1m/README            \n",
            "  inflating: ml-1m/users.dat         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j24pjXi6tMs6",
        "colab_type": "text"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIFR-8xl-kQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class rsdataset(Dataset):\n",
        "    def __init__(self, usersfile, moviesfile, ratingsfile, nrows=None):\n",
        "        \n",
        "        # Read files\n",
        "        self.movies = pd.read_csv(moviesfile, sep='::', names=['MovieID', 'Title', 'Genres'], engine='python')\n",
        "        self.users = pd.read_csv(usersfile, sep='::', names=['UserID', 'Gender', 'Age', 'Occupation', 'Zipcode'], engine='python')\n",
        "        self.ratings = pd.read_csv(ratingsfile, sep='::', names=['UserID', 'MovieID', 'Rating', 'Timestamp'], engine='python', nrows=nrows)\n",
        "        \n",
        "        assert self.users['UserID'].nunique() >= self.ratings['UserID'].nunique(), 'UserID with unknown information'\n",
        "        assert self.movies['MovieID'].nunique() >= self.ratings['MovieID'].nunique(), 'Movies with unknown information'\n",
        "\n",
        "        self.users_emb_columns = []\n",
        "        self.users_ohe_columns = []\n",
        "        self.movies_emb_columns = []\n",
        "        self.movies_ohe_columns = []\n",
        "        self.interact_columns = []\n",
        "\n",
        "        self.nusers = self.ratings['UserID'].nunique()\n",
        "        self.nmovies = self.ratings['MovieID'].nunique()\n",
        "\n",
        "        self.y_range = (self.ratings['Rating'].min(), self.ratings['Rating'].max())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        What have we learned regarding tensors and GPU memory\n",
        "        -----------------------------------------------------\n",
        "        I used to transfer one big chunk of data from RAM to cpu/gpu ... It\n",
        "        was very long because it took time. The problem was that ohe are encoded in int64.\n",
        "\n",
        "        It was the same thing for cpu and gpu. I thought that gpu would be longer because it has\n",
        "        to transfer different memory bus probably? But it was the same thing with the CPU, very long\n",
        "\n",
        "        I tried pinned_memory=True in the dataloader, and it was the same thing.\n",
        "\n",
        "        I shipped everything in memory and in __getitem__ I sliced everything after.\n",
        "        I saved a few seconds (5 seconds)\n",
        "\n",
        "        One of the biggest increase was when all the dataset was transformed in 5 tensors.\n",
        "        I tried changing num_workers and the speed increased a lot. \n",
        "\n",
        "        \"\"\"\n",
        "        return (((self.users_emb[idx])),\n",
        "                ((self.users_ohe[idx])),\n",
        "                ((self.movies_emb[idx])),\n",
        "                ((self.movies_ohe[idx])),\n",
        "                ((self.interact[idx]))), (self.y[idx])\n",
        "\n",
        "    def to_tensor(self):\n",
        "        self.users_emb = torch.from_numpy(self.ratings[self.users_emb_columns].values)\n",
        "        self.users_ohe = torch.from_numpy(self.ratings[self.users_ohe_columns].values)\n",
        "        self.movies_emb = torch.from_numpy(self.ratings[self.movies_emb_columns].values)\n",
        "        self.movies_ohe = torch.from_numpy(self.ratings[self.movies_ohe_columns].values)\n",
        "        self.interact = torch.from_numpy(self.ratings[self.interact_columns].values)\n",
        "        self.y = torch.tensor(self.y.values, dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uINDlkiMB_Fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = rsdataset('ml-1m/users.dat', 'ml-1m/movies.dat', 'ml-1m/ratings.dat', nrows=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8ivFYVSM3nr",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing of dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_w1QQER37El",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.ratings = train.ratings.merge(train.movies, left_on='MovieID', right_on='MovieID')\n",
        "train.movies = train.ratings[train.movies.columns]\n",
        "\n",
        "train.ratings = train.ratings.merge(train.users, left_on='UserID', right_on='UserID')\n",
        "train.users = train.ratings[train.users.columns]\n",
        "\n",
        "train.y = train.ratings['Rating']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlQhqnXOYcmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Label Encode users\n",
        "#columns = ['UserID', 'Gender', 'Age', 'Occupation', 'Zipcode']\n",
        "columns = ['UserID', 'Gender', 'Age', 'Occupation']\n",
        "train.ratings[columns] = train.ratings[columns].apply(preprocessing.LabelEncoder().fit_transform)\n",
        "#train.ratings[columns] = train.ratings[columns].astype('object')\n",
        "train.users_emb_columns = train.users_emb_columns + columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ3jSa_dRMLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Label Encode movies\n",
        "columns = ['MovieID']\n",
        "train.ratings[columns] = train.ratings[columns].apply(preprocessing.LabelEncoder().fit_transform)\n",
        "#train.ratings[columns] = train.ratings[columns].astype('object')\n",
        "train.movies_emb_columns = train.movies_emb_columns + columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2XcLbiz9lql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One Hot Encode users\n",
        "#columns = ['Gender', 'Age', 'Occupation', 'Zipcode']\n",
        "columns = ['Gender', 'Age', 'Occupation']\n",
        "ohe = preprocessing.OneHotEncoder(categories='auto', sparse=False, dtype='int8')\n",
        "ohe.fit(train.ratings[columns])\n",
        "train.ratings = pd.concat([train.ratings, pd.DataFrame(data=ohe.transform(train.ratings[columns]), columns=ohe.get_feature_names(columns))], axis=1)\n",
        "train.users_ohe_columns = train.users_ohe_columns + columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfVq6sd5NqiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One Hot Encode movies (non exclusive)\n",
        "genres = ['Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', \n",
        "          'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
        "\n",
        "for genre in genres:\n",
        "    column = 'Genre_' + str(genre)\n",
        "    train.ratings[column] = train.ratings['Genres'].apply(lambda x: 1 if genre in x else 0)\n",
        "    train.movies_ohe_columns.append(column)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTH7wNbZp_jA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interact = patsy.dmatrix(\"0 + Gender:Age + Gender:Occupation + Age:Occupation\", data=train.ratings.astype('object'), return_type='dataframe').astype('int8')\n",
        "train.ratings = pd.concat([train.ratings, interact], axis=1)\n",
        "train.interact_columns = interact.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRSGsdEmMlPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop unused columns\n",
        "train.movies.drop(['Title', 'Genres'], inplace=True, axis=1)\n",
        "train.ratings.drop(['Title', 'Genres', 'Zipcode'], inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPTkxLKQMWhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.to_tensor()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm1qo9It3zsb",
        "colab_type": "text"
      },
      "source": [
        "### DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNXPv9DAmHBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split\n",
        "train_size = int(0.8 * len(train))\n",
        "test_size = len(train) - train_size\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(train, [train_size, test_size])\n",
        "\n",
        "# Create dataloaders\n",
        "dataloaders = {}\n",
        "dataloaders['train'] = torch.utils.data.DataLoader(train_dataset, batch_size=4096, shuffle=True)\n",
        "dataloaders['valid'] = torch.utils.data.DataLoader(valid_dataset, batch_size=4096, shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa-KNh5qkUh8",
        "colab_type": "text"
      },
      "source": [
        "### Define structure of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daekeS2zju4B",
        "colab_type": "code",
        "outputId": "066d0111-a05c-4d8d-96df-06294888e231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "class deepnwide(nn.Module):\n",
        "    def __init__(self, users_emb, movies_emb, users_ohe, movies_ohe, interact, nemb, size_emb, y_range, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.name = 'deepnwide'\n",
        "        self.y_range = y_range\n",
        "\n",
        "        # wide\n",
        "        # ohe part - We don't need to specify nothing here\n",
        "        \n",
        "        # deep\n",
        "        self.emb_UserID = nn.Embedding(len(torch.unique(users_emb[:, 0])), size_emb)\n",
        "        self.emb_UserID.weight.data.uniform_(-.01, .01)\n",
        "        self.emb_Gender = nn.Embedding(len(torch.unique(users_emb[:, 1])), size_emb)\n",
        "        self.emb_Gender.weight.data.uniform_(-.01, .01)\n",
        "        self.emb_Age = nn.Embedding(len(torch.unique(users_emb[:, 2])), size_emb)\n",
        "        self.emb_Age.weight.data.uniform_(-.01, .01)\n",
        "        self.emb_Occupation = nn.Embedding(len(torch.unique(users_emb[:, 3])), size_emb)\n",
        "        self.emb_Occupation.weight.data.uniform_(-.01, .01)\n",
        "        self.emb_MovieID = nn.Embedding(len(torch.unique(movies_emb[:, 0])), size_emb)\n",
        "        self.emb_MovieID.weight.data.uniform_(-.01, .01)\n",
        "\n",
        "        # hidden layers\n",
        "        self.h1 = nn.Linear(nemb * size_emb, 100)\n",
        "        self.h2 = nn.Linear(100, 100)\n",
        "        self.h3 = nn.Linear(100, 100)\n",
        "\n",
        "        # Dropout layers\n",
        "        self.dropout1 = nn.Dropout(p=dropout)\n",
        "        self.dropout2 = nn.Dropout(p=dropout)\n",
        "        self.dropout3 = nn.Dropout(p=dropout)\n",
        "\n",
        "        # final dense layer \n",
        "        self.last_layer = nn.Linear((interact.shape[1]) + (movies_ohe.shape[1]) + (100), 1)\n",
        "\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Classic Matrix Factorization with bias term.\n",
        "        MSE: 1.07\n",
        "        \"\"\"\n",
        "        # Assign data\n",
        "        user_emb = X[0]\n",
        "        user_ohe = X[1]\n",
        "        movie_emb = X[2]\n",
        "        movie_ohe = X[3]\n",
        "        interact = X[4]\n",
        "        \n",
        "        UserID = user_emb[:, 0]\n",
        "        Gender = user_emb[:, 1]\n",
        "        Age = user_emb[:, 2]\n",
        "        Occupation = user_emb[:, 3]\n",
        "        MovieID = movie_emb[:, 0]\n",
        "\n",
        "        UserID = self.emb_UserID(UserID)\n",
        "        Gender = self.emb_Gender(Gender)\n",
        "        Age = self.emb_Age(Age)\n",
        "        Occupation = self.emb_Occupation(Occupation)\n",
        "        MovieID = self.emb_MovieID(MovieID)\n",
        "\n",
        "        emb = torch.cat([UserID,\n",
        "                         Age,\n",
        "                         Gender,\n",
        "                         Occupation,\n",
        "                         MovieID],\n",
        "                         dim=1)\n",
        "        \n",
        "        emb = F.relu(self.dropout1(self.h1(emb)))\n",
        "        emb = F.relu(self.dropout2(self.h2(emb)))\n",
        "        emb = F.relu(self.dropout3(self.h3(emb)))\n",
        "\n",
        "        result = self.last_layer(torch.cat([interact.float(), movie_ohe.float(), emb.float()], dim=1))\n",
        "\n",
        "        return (torch.sigmoid(result) * (self.y_range[1]-self.y_range[0]) + self.y_range[0]).squeeze()\n",
        "\n",
        "\n",
        "model = deepnwide(train.users_emb, train.movies_emb, train.users_ohe, train.movies_ohe, train.interact, 5, 60, train.y_range, 0.5)\n",
        "model.to(device)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deepnwide(\n",
            "  (emb_UserID): Embedding(6040, 60)\n",
            "  (emb_Gender): Embedding(2, 60)\n",
            "  (emb_Age): Embedding(7, 60)\n",
            "  (emb_Occupation): Embedding(21, 60)\n",
            "  (emb_MovieID): Embedding(3706, 60)\n",
            "  (h1): Linear(in_features=300, out_features=100, bias=True)\n",
            "  (h2): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (h3): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (dropout1): Dropout(p=0.5)\n",
            "  (dropout2): Dropout(p=0.5)\n",
            "  (dropout3): Dropout(p=0.5)\n",
            "  (last_layer): Linear(in_features=292, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MftgRHZB3rFd",
        "colab_type": "code",
        "outputId": "a2c9651e-2867-49ab-af8a-6479828a8fac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "class twoembeds(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    The best results that we were able to achieve on a randomly split test dataset of size 0.2:\n",
        "    - embsize: 30\n",
        "    - LR: 0.005 with LRstep of gamma 0.1 step size 7\n",
        "    - batch size of 4096\n",
        "\n",
        "    Results:\n",
        "    epoch:18\n",
        "    RMSE: 0.8578\n",
        "    train MSE: 0.5658\n",
        "    valid MSE: 0.7359\n",
        "    dur: 25.3224    \n",
        "    \"\"\"\n",
        "    def __init__(self, size_emb):\n",
        "        super().__init__()\n",
        "\n",
        "        # set name of model\n",
        "        self.name = 'twoembeds'\n",
        "\n",
        "        # User and movie embeddings\n",
        "        self.emb_UserID = nn.Embedding(train.nusers, size_emb)\n",
        "        self.emb_MovieID = nn.Embedding(train.nmovies, size_emb)\n",
        "        self.emb_UserID.weight.data.uniform_(-.01, .01)\n",
        "        self.emb_MovieID.weight.data.uniform_(-.01, .01)\n",
        "        \n",
        "        # User and movie embeddings weights\n",
        "        self.emb_UserID_b = nn.Embedding(train.nusers, 1)\n",
        "        self.emb_MovieID_b = nn.Embedding(train.nmovies, 1)\n",
        "        self.emb_UserID_b.weight.data.uniform_(-.01, .01)\n",
        "        self.emb_MovieID_b.weight.data.uniform_(-.01, .01)\n",
        " \n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Classic Matrix Factorization with bias term.\n",
        "        Best RMSE on validation dataset: ~1.08\n",
        "        \"\"\"\n",
        "        user_emb = X[0]\n",
        "        user_ohe = X[1]\n",
        "        movie_emb = X[2]\n",
        "        movie_ohe = X[3]\n",
        "        interact = X[4]\n",
        "\n",
        "        UserID = user_emb[:, 0]\n",
        "        MovieID = movie_emb[:, 0]\n",
        "\n",
        "        user_emb = self.emb_UserID(UserID)\n",
        "        movie_emb = self.emb_MovieID(MovieID)\n",
        "\n",
        "        mult = (user_emb * movie_emb).sum(1)\n",
        "\n",
        "        # add bias\n",
        "        multb = mult + self.emb_UserID_b(UserID).squeeze() + self.emb_MovieID_b(MovieID).squeeze()\n",
        "\n",
        "        multb = multb.float()\n",
        "\n",
        "        return multb\n",
        "\n",
        "\n",
        "model = twoembeds(15)\n",
        "model.to(device)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "twoembeds(\n",
            "  (emb_UserID): Embedding(6040, 15)\n",
            "  (emb_MovieID): Embedding(3706, 15)\n",
            "  (emb_UserID_b): Embedding(6040, 1)\n",
            "  (emb_MovieID_b): Embedding(3706, 1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rBEpoBPd4w5",
        "colab_type": "text"
      },
      "source": [
        "### Skorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9XsVtTYOqGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Earlystopping callback\n",
        "earlystopping = EarlyStopping(monitor='valid_loss', patience=10, threshold=0.005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ockpmqrz9KYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RMSE callback\n",
        "def rmseloss(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "rmse_scorer = make_scorer(rmseloss)\n",
        "\n",
        "epoch_rmse = EpochScoring(rmse_scorer, name='rmse_score', lower_is_better=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p62gAk8FgaZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checkpoint callback\n",
        "checkpoint = Checkpoint(monitor='rmse_score_best', f_params='params.pt', f_optimizer='optimizer.pt', f_history='history.json', f_pickle='model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knAy1XQYjgze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Learning rate scheduler callback\n",
        "lr_scheduler = LRScheduler(policy=\"StepLR\", step_size=7, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy29DspnXU-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Progressbar callback\n",
        "progressbar = ProgressBar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4yfIEH2rPZE",
        "colab_type": "code",
        "outputId": "af7fad5c-f72c-4a7c-f302-0edf072bf0ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Tensorboard\n",
        "!rm -rf runs/*\n",
        "writer = SummaryWriter()\n",
        "%tensorboard --logdir 'runs/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 9725), started 1:31:28 ago. (Use '!kill 9725' to kill it.)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6006\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 800));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgVTuwedriTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deepnwidenet = NeuralNet(\n",
        "    deepnwide,\n",
        "    module__users_emb=train.users_emb,\n",
        "    module__movies_emb=train.movies_emb,\n",
        "    module__users_ohe=train.users_ohe,\n",
        "    module__movies_ohe=train.movies_ohe,\n",
        "    module__interact=train.interact,\n",
        "    module__nemb=5,\n",
        "    module__size_emb=60,\n",
        "    module__y_range=train.y_range,\n",
        "    module__dropout=0.4,\n",
        "    max_epochs=30,\n",
        "    lr=0.01,\n",
        "    optimizer=torch.optim.Adam,\n",
        "    criterion=torch.nn.MSELoss,\n",
        "    device=device,\n",
        "    iterator_train__batch_size=4096,\n",
        "    iterator_train__num_workers=4,\n",
        "    iterator_train__shuffle=True,\n",
        "    iterator_valid__batch_size=4096,\n",
        "    train_split=predefined_split(valid_dataset),\n",
        "    callbacks=[\n",
        "               earlystopping,\n",
        "               epoch_rmse,\n",
        "               #checkpoint,\n",
        "               lr_scheduler,\n",
        "               #TensorBoard(writer),\n",
        "               #progressbar\n",
        "               ]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6qm5_snshUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#deepnwidenet.fit(train_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4Ecaxc4euD1",
        "colab_type": "code",
        "outputId": "2cea73fa-450e-48aa-8b0f-77e47127abda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "params = {\n",
        "    'lr': [0.001, 0.01, 0.005],\n",
        "    'module__size_emb': [20, 30, 60, 120],\n",
        "    'module__dropout': [0.2, 0.5]\n",
        "}\n",
        "gs = GridSearchCV(deepnwidenet,\n",
        "                  params,\n",
        "                  verbose=50,\n",
        "                  refit=False,\n",
        "                  #n_jobs=2,\n",
        "                  #pre_dispatch=2,\n",
        "                  cv=3,\n",
        "                  scoring='neg_mean_squared_error')\n",
        "\n",
        "X_ds = SliceDataset(train, idx=0)\n",
        "y_ds = SliceDataset(train, idx=1)\n",
        "gs.fit(X_ds, y_ds)\n",
        "\n",
        "print(gs.best_score_, gs.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[CV] lr=0.001, module__dropout=0.2, module__size_emb=20 ..............\n",
            "  epoch    rmse_score    train_loss    valid_loss      dur\n",
            "-------  ------------  ------------  ------------  -------\n",
            "      1        \u001b[36m0.9342\u001b[0m        \u001b[32m1.0503\u001b[0m        \u001b[35m0.8726\u001b[0m  39.3537\n",
            "      2        \u001b[36m0.9227\u001b[0m        \u001b[32m0.8470\u001b[0m        \u001b[35m0.8513\u001b[0m  40.0974\n",
            "      3        \u001b[36m0.9162\u001b[0m        \u001b[32m0.8260\u001b[0m        \u001b[35m0.8394\u001b[0m  40.3790\n",
            "      4        \u001b[36m0.9124\u001b[0m        \u001b[32m0.8133\u001b[0m        \u001b[35m0.8325\u001b[0m  40.4218\n",
            "      5        \u001b[36m0.9103\u001b[0m        \u001b[32m0.8067\u001b[0m        \u001b[35m0.8286\u001b[0m  41.0082\n",
            "      6        \u001b[36m0.9063\u001b[0m        \u001b[32m0.7985\u001b[0m        \u001b[35m0.8213\u001b[0m  40.9752\n",
            "      7        \u001b[36m0.9011\u001b[0m        \u001b[32m0.7880\u001b[0m        \u001b[35m0.8120\u001b[0m  41.0151\n",
            "      8        \u001b[36m0.8971\u001b[0m        \u001b[32m0.7768\u001b[0m        \u001b[35m0.8048\u001b[0m  40.8253\n",
            "      9        \u001b[36m0.8952\u001b[0m        \u001b[32m0.7536\u001b[0m        \u001b[35m0.8013\u001b[0m  40.7661\n",
            "     10        \u001b[36m0.8943\u001b[0m        \u001b[32m0.7503\u001b[0m        \u001b[35m0.7997\u001b[0m  40.9498\n",
            "     11        \u001b[36m0.8935\u001b[0m        \u001b[32m0.7482\u001b[0m        \u001b[35m0.7984\u001b[0m  41.0464\n",
            "     12        \u001b[36m0.8929\u001b[0m        \u001b[32m0.7464\u001b[0m        \u001b[35m0.7974\u001b[0m  41.0715\n",
            "     13        \u001b[36m0.8924\u001b[0m        \u001b[32m0.7442\u001b[0m        \u001b[35m0.7964\u001b[0m  40.8152\n",
            "     14        \u001b[36m0.8920\u001b[0m        \u001b[32m0.7433\u001b[0m        \u001b[35m0.7956\u001b[0m  41.0147\n",
            "     15        \u001b[36m0.8914\u001b[0m        \u001b[32m0.7412\u001b[0m        \u001b[35m0.7946\u001b[0m  40.6666\n",
            "     16        \u001b[36m0.8914\u001b[0m        \u001b[32m0.7386\u001b[0m        \u001b[35m0.7945\u001b[0m  40.7697\n",
            "     17        \u001b[36m0.8913\u001b[0m        \u001b[32m0.7382\u001b[0m        \u001b[35m0.7945\u001b[0m  41.4328\n",
            "     18        \u001b[36m0.8913\u001b[0m        \u001b[32m0.7381\u001b[0m        \u001b[35m0.7944\u001b[0m  41.3822\n",
            "     19        \u001b[36m0.8913\u001b[0m        \u001b[32m0.7380\u001b[0m        \u001b[35m0.7944\u001b[0m  41.0760\n",
            "     20        \u001b[36m0.8912\u001b[0m        \u001b[32m0.7376\u001b[0m        \u001b[35m0.7943\u001b[0m  41.2615\n",
            "     21        \u001b[36m0.8912\u001b[0m        0.7385        \u001b[35m0.7942\u001b[0m  40.9229\n",
            "     22        \u001b[36m0.8911\u001b[0m        0.7380        \u001b[35m0.7941\u001b[0m  40.7005\n",
            "     23        \u001b[36m0.8911\u001b[0m        \u001b[32m0.7371\u001b[0m        \u001b[35m0.7941\u001b[0m  41.7663\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV]  lr=0.001, module__dropout=0.2, module__size_emb=20, score=-0.934, total=20.5min\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 20.5min remaining:    0.0s\n",
            "[CV] lr=0.001, module__dropout=0.2, module__size_emb=20 ..............\n",
            "  epoch    rmse_score    train_loss    valid_loss      dur\n",
            "-------  ------------  ------------  ------------  -------\n",
            "      1        \u001b[36m0.9285\u001b[0m        \u001b[32m1.0243\u001b[0m        \u001b[35m0.8621\u001b[0m  39.5348\n",
            "      2        \u001b[36m0.9181\u001b[0m        \u001b[32m0.8231\u001b[0m        \u001b[35m0.8429\u001b[0m  40.2444\n",
            "      3        \u001b[36m0.9131\u001b[0m        \u001b[32m0.8019\u001b[0m        \u001b[35m0.8337\u001b[0m  40.2020\n",
            "      4        \u001b[36m0.9108\u001b[0m        \u001b[32m0.7920\u001b[0m        \u001b[35m0.8295\u001b[0m  40.5219\n",
            "      5        \u001b[36m0.9075\u001b[0m        \u001b[32m0.7854\u001b[0m        \u001b[35m0.8236\u001b[0m  42.4495\n",
            "      6        \u001b[36m0.9030\u001b[0m        \u001b[32m0.7758\u001b[0m        \u001b[35m0.8154\u001b[0m  41.4817\n",
            "      7        \u001b[36m0.8995\u001b[0m        \u001b[32m0.7663\u001b[0m        \u001b[35m0.8091\u001b[0m  41.2048\n",
            "      8        \u001b[36m0.8959\u001b[0m        \u001b[32m0.7567\u001b[0m        \u001b[35m0.8027\u001b[0m  41.4235\n",
            "      9        \u001b[36m0.8937\u001b[0m        \u001b[32m0.7343\u001b[0m        \u001b[35m0.7986\u001b[0m  42.5218\n",
            "     10        \u001b[36m0.8926\u001b[0m        \u001b[32m0.7313\u001b[0m        \u001b[35m0.7968\u001b[0m  40.9249\n",
            "     11        \u001b[36m0.8919\u001b[0m        \u001b[32m0.7287\u001b[0m        \u001b[35m0.7955\u001b[0m  41.0967\n",
            "     12        \u001b[36m0.8913\u001b[0m        \u001b[32m0.7268\u001b[0m        \u001b[35m0.7944\u001b[0m  40.9405\n",
            "     13        \u001b[36m0.8911\u001b[0m        \u001b[32m0.7252\u001b[0m        \u001b[35m0.7941\u001b[0m  40.5265\n",
            "     14        \u001b[36m0.8903\u001b[0m        \u001b[32m0.7240\u001b[0m        \u001b[35m0.7926\u001b[0m  40.6693\n",
            "     15        \u001b[36m0.8897\u001b[0m        \u001b[32m0.7217\u001b[0m        \u001b[35m0.7915\u001b[0m  40.9908\n",
            "     16        \u001b[36m0.8896\u001b[0m        \u001b[32m0.7186\u001b[0m        \u001b[35m0.7915\u001b[0m  40.6808\n",
            "     17        \u001b[36m0.8896\u001b[0m        \u001b[32m0.7185\u001b[0m        \u001b[35m0.7914\u001b[0m  40.8313\n",
            "     18        \u001b[36m0.8896\u001b[0m        \u001b[32m0.7183\u001b[0m        \u001b[35m0.7914\u001b[0m  40.3756\n",
            "     19        \u001b[36m0.8896\u001b[0m        0.7185        \u001b[35m0.7914\u001b[0m  40.6230\n",
            "     20        0.8896        \u001b[32m0.7181\u001b[0m        0.7914  40.8991\n",
            "     21        \u001b[36m0.8895\u001b[0m        \u001b[32m0.7177\u001b[0m        \u001b[35m0.7912\u001b[0m  41.1101\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV]  lr=0.001, module__dropout=0.2, module__size_emb=20, score=-0.969, total=18.9min\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 39.4min remaining:    0.0s\n",
            "[CV] lr=0.001, module__dropout=0.2, module__size_emb=20 ..............\n",
            "  epoch    rmse_score    train_loss    valid_loss      dur\n",
            "-------  ------------  ------------  ------------  -------\n",
            "      1        \u001b[36m0.9347\u001b[0m        \u001b[32m1.0148\u001b[0m        \u001b[35m0.8736\u001b[0m  40.4865\n",
            "      2        \u001b[36m0.9258\u001b[0m        \u001b[32m0.8122\u001b[0m        \u001b[35m0.8572\u001b[0m  40.8944\n",
            "      3        \u001b[36m0.9222\u001b[0m        \u001b[32m0.7927\u001b[0m        \u001b[35m0.8504\u001b[0m  40.6602\n",
            "      4        \u001b[36m0.9193\u001b[0m        \u001b[32m0.7822\u001b[0m        \u001b[35m0.8452\u001b[0m  41.3469\n",
            "      5        \u001b[36m0.9169\u001b[0m        \u001b[32m0.7757\u001b[0m        \u001b[35m0.8407\u001b[0m  41.0475\n",
            "      6        \u001b[36m0.9147\u001b[0m        \u001b[32m0.7672\u001b[0m        \u001b[35m0.8366\u001b[0m  41.6350\n",
            "      7        \u001b[36m0.9087\u001b[0m        \u001b[32m0.7570\u001b[0m        \u001b[35m0.8258\u001b[0m  41.1662\n",
            "      8        \u001b[36m0.9057\u001b[0m        \u001b[32m0.7471\u001b[0m        \u001b[35m0.8202\u001b[0m  41.2742\n",
            "      9        \u001b[36m0.9038\u001b[0m        \u001b[32m0.7270\u001b[0m        \u001b[35m0.8169\u001b[0m  41.1313\n",
            "     10        \u001b[36m0.9027\u001b[0m        \u001b[32m0.7241\u001b[0m        \u001b[35m0.8149\u001b[0m  41.3254\n",
            "     11        \u001b[36m0.9021\u001b[0m        \u001b[32m0.7220\u001b[0m        \u001b[35m0.8138\u001b[0m  42.4892\n",
            "     12        \u001b[36m0.9011\u001b[0m        \u001b[32m0.7201\u001b[0m        \u001b[35m0.8120\u001b[0m  43.0913\n",
            "     13        \u001b[36m0.9005\u001b[0m        \u001b[32m0.7188\u001b[0m        \u001b[35m0.8108\u001b[0m  42.7190\n",
            "     14        \u001b[36m0.9002\u001b[0m        \u001b[32m0.7166\u001b[0m        \u001b[35m0.8104\u001b[0m  42.6706\n",
            "     15        \u001b[36m0.8996\u001b[0m        \u001b[32m0.7155\u001b[0m        \u001b[35m0.8094\u001b[0m  42.5905\n",
            "     16        \u001b[36m0.8994\u001b[0m        \u001b[32m0.7126\u001b[0m        \u001b[35m0.8089\u001b[0m  41.8900\n",
            "     17        \u001b[36m0.8992\u001b[0m        0.7127        \u001b[35m0.8086\u001b[0m  41.4257\n",
            "     18        0.8994        0.7126        0.8089  41.8777\n",
            "     19        0.8993        0.7128        0.8088  41.7914\n",
            "     20        0.8993        \u001b[32m0.7123\u001b[0m        0.8087  41.4296\n",
            "     21        0.8994        \u001b[32m0.7119\u001b[0m        0.8089  41.6662\n",
            "     22        \u001b[36m0.8991\u001b[0m        \u001b[32m0.7118\u001b[0m        \u001b[35m0.8085\u001b[0m  41.6634\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV]  lr=0.001, module__dropout=0.2, module__size_emb=20, score=-1.033, total=20.1min\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 59.4min remaining:    0.0s\n",
            "[CV] lr=0.001, module__dropout=0.2, module__size_emb=30 ..............\n",
            "  epoch    rmse_score    train_loss    valid_loss      dur\n",
            "-------  ------------  ------------  ------------  -------\n",
            "      1        \u001b[36m0.9314\u001b[0m        \u001b[32m1.0378\u001b[0m        \u001b[35m0.8675\u001b[0m  42.3854\n",
            "      2        \u001b[36m0.9228\u001b[0m        \u001b[32m0.8459\u001b[0m        \u001b[35m0.8516\u001b[0m  43.1377\n",
            "      3        \u001b[36m0.9159\u001b[0m        \u001b[32m0.8268\u001b[0m        \u001b[35m0.8389\u001b[0m  44.0309\n",
            "      4        \u001b[36m0.9126\u001b[0m        \u001b[32m0.8143\u001b[0m        \u001b[35m0.8329\u001b[0m  45.0065\n",
            "      5        \u001b[36m0.9090\u001b[0m        \u001b[32m0.8059\u001b[0m        \u001b[35m0.8263\u001b[0m  44.9087\n",
            "      6        \u001b[36m0.9049\u001b[0m        \u001b[32m0.7968\u001b[0m        \u001b[35m0.8189\u001b[0m  43.7002\n",
            "      7        \u001b[36m0.9007\u001b[0m        \u001b[32m0.7867\u001b[0m        \u001b[35m0.8112\u001b[0m  42.5744\n",
            "      8        \u001b[36m0.8965\u001b[0m        \u001b[32m0.7760\u001b[0m        \u001b[35m0.8037\u001b[0m  44.7066\n",
            "      9        \u001b[36m0.8942\u001b[0m        \u001b[32m0.7519\u001b[0m        \u001b[35m0.7996\u001b[0m  45.2610\n",
            "     10        \u001b[36m0.8930\u001b[0m        \u001b[32m0.7484\u001b[0m        \u001b[35m0.7975\u001b[0m  43.9028\n",
            "     11        \u001b[36m0.8924\u001b[0m        \u001b[32m0.7462\u001b[0m        \u001b[35m0.7964\u001b[0m  43.6373\n",
            "     12        \u001b[36m0.8915\u001b[0m        \u001b[32m0.7439\u001b[0m        \u001b[35m0.7948\u001b[0m  44.4665\n",
            "     13        \u001b[36m0.8909\u001b[0m        \u001b[32m0.7417\u001b[0m        \u001b[35m0.7937\u001b[0m  44.3511\n",
            "     14        \u001b[36m0.8903\u001b[0m        \u001b[32m0.7398\u001b[0m        \u001b[35m0.7927\u001b[0m  44.1775\n",
            "     15        \u001b[36m0.8898\u001b[0m        \u001b[32m0.7383\u001b[0m        \u001b[35m0.7918\u001b[0m  44.1795\n",
            "     16        \u001b[36m0.8898\u001b[0m        \u001b[32m0.7349\u001b[0m        \u001b[35m0.7917\u001b[0m  45.3980\n",
            "     17        \u001b[36m0.8897\u001b[0m        0.7352        \u001b[35m0.7916\u001b[0m  45.1554\n",
            "     18        \u001b[36m0.8896\u001b[0m        \u001b[32m0.7345\u001b[0m        \u001b[35m0.7914\u001b[0m  45.4347\n",
            "     19        \u001b[36m0.8896\u001b[0m        \u001b[32m0.7341\u001b[0m        \u001b[35m0.7913\u001b[0m  44.7204\n",
            "     20        \u001b[36m0.8895\u001b[0m        \u001b[32m0.7339\u001b[0m        \u001b[35m0.7912\u001b[0m  44.7115\n",
            "     21        \u001b[36m0.8894\u001b[0m        \u001b[32m0.7339\u001b[0m        \u001b[35m0.7911\u001b[0m  44.7232\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV]  lr=0.001, module__dropout=0.2, module__size_emb=30, score=-0.933, total=20.5min\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 80.0min remaining:    0.0s\n",
            "[CV] lr=0.001, module__dropout=0.2, module__size_emb=30 ..............\n",
            "  epoch    rmse_score    train_loss    valid_loss      dur\n",
            "-------  ------------  ------------  ------------  -------\n",
            "      1        \u001b[36m0.9280\u001b[0m        \u001b[32m1.0229\u001b[0m        \u001b[35m0.8612\u001b[0m  43.3932\n",
            "      2        \u001b[36m0.9183\u001b[0m        \u001b[32m0.8220\u001b[0m        \u001b[35m0.8432\u001b[0m  43.8797\n",
            "      3        \u001b[36m0.9137\u001b[0m        \u001b[32m0.8021\u001b[0m        \u001b[35m0.8349\u001b[0m  43.2877\n",
            "      4        \u001b[36m0.9081\u001b[0m        \u001b[32m0.7905\u001b[0m        \u001b[35m0.8246\u001b[0m  42.4537\n",
            "      5        \u001b[36m0.9032\u001b[0m        \u001b[32m0.7774\u001b[0m        \u001b[35m0.8158\u001b[0m  43.3001\n",
            "      6        \u001b[36m0.8985\u001b[0m        \u001b[32m0.7663\u001b[0m        \u001b[35m0.8072\u001b[0m  43.2670\n",
            "      7        \u001b[36m0.8952\u001b[0m        \u001b[32m0.7547\u001b[0m        \u001b[35m0.8014\u001b[0m  43.4909\n",
            "      8        \u001b[36m0.8921\u001b[0m        \u001b[32m0.7459\u001b[0m        \u001b[35m0.7958\u001b[0m  43.9256\n",
            "      9        \u001b[36m0.8907\u001b[0m        \u001b[32m0.7228\u001b[0m        \u001b[35m0.7934\u001b[0m  43.5595\n",
            "     10        \u001b[36m0.8900\u001b[0m        \u001b[32m0.7200\u001b[0m        \u001b[35m0.7921\u001b[0m  43.3114\n",
            "     11        \u001b[36m0.8889\u001b[0m        \u001b[32m0.7177\u001b[0m        \u001b[35m0.7902\u001b[0m  44.5269\n",
            "     12        \u001b[36m0.8885\u001b[0m        \u001b[32m0.7162\u001b[0m        \u001b[35m0.7894\u001b[0m  44.4222\n",
            "     13        \u001b[36m0.8883\u001b[0m        \u001b[32m0.7153\u001b[0m        \u001b[35m0.7890\u001b[0m  44.3017\n",
            "     14        \u001b[36m0.8875\u001b[0m        \u001b[32m0.7137\u001b[0m        \u001b[35m0.7876\u001b[0m  45.5462\n",
            "     15        \u001b[36m0.8874\u001b[0m        \u001b[32m0.7123\u001b[0m        \u001b[35m0.7874\u001b[0m  44.9707\n",
            "     16        \u001b[36m0.8873\u001b[0m        \u001b[32m0.7091\u001b[0m        \u001b[35m0.7874\u001b[0m  43.9342\n",
            "     17        \u001b[36m0.8872\u001b[0m        \u001b[32m0.7090\u001b[0m        \u001b[35m0.7872\u001b[0m  46.0992\n",
            "     18        0.8872        \u001b[32m0.7089\u001b[0m        0.7872  43.8853\n",
            "     19        \u001b[36m0.8871\u001b[0m        \u001b[32m0.7083\u001b[0m        \u001b[35m0.7870\u001b[0m  42.6093\n",
            "     20        \u001b[36m0.8871\u001b[0m        \u001b[32m0.7083\u001b[0m        \u001b[35m0.7869\u001b[0m  42.9697\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV]  lr=0.001, module__dropout=0.2, module__size_emb=30, score=-0.975, total=19.4min\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 99.3min remaining:    0.0s\n",
            "[CV] lr=0.001, module__dropout=0.2, module__size_emb=30 ..............\n",
            "  epoch    rmse_score    train_loss    valid_loss      dur\n",
            "-------  ------------  ------------  ------------  -------\n",
            "      1        \u001b[36m0.9330\u001b[0m        \u001b[32m0.9846\u001b[0m        \u001b[35m0.8706\u001b[0m  40.9460\n",
            "      2        \u001b[36m0.9247\u001b[0m        \u001b[32m0.8077\u001b[0m        \u001b[35m0.8551\u001b[0m  41.4109\n",
            "      3        \u001b[36m0.9224\u001b[0m        \u001b[32m0.7887\u001b[0m        \u001b[35m0.8509\u001b[0m  41.6993\n",
            "      4        \u001b[36m0.9194\u001b[0m        \u001b[32m0.7812\u001b[0m        \u001b[35m0.8453\u001b[0m  42.1243\n",
            "      5        \u001b[36m0.9146\u001b[0m        \u001b[32m0.7737\u001b[0m        \u001b[35m0.8365\u001b[0m  42.5295\n",
            "      6        \u001b[36m0.9104\u001b[0m        \u001b[32m0.7631\u001b[0m        \u001b[35m0.8288\u001b[0m  41.6290\n",
            "      7        \u001b[36m0.9071\u001b[0m        \u001b[32m0.7526\u001b[0m        \u001b[35m0.8229\u001b[0m  42.7419\n",
            "      8        \u001b[36m0.9051\u001b[0m        \u001b[32m0.7434\u001b[0m        \u001b[35m0.8193\u001b[0m  42.3670\n",
            "      9        \u001b[36m0.9038\u001b[0m        \u001b[32m0.7232\u001b[0m        \u001b[35m0.8168\u001b[0m  42.3134\n",
            "     10        \u001b[36m0.9031\u001b[0m        \u001b[32m0.7198\u001b[0m        \u001b[35m0.8155\u001b[0m  42.5982\n",
            "     11        \u001b[36m0.9026\u001b[0m        \u001b[32m0.7182\u001b[0m        \u001b[35m0.8146\u001b[0m  41.9379\n",
            "     12        \u001b[36m0.9021\u001b[0m        \u001b[32m0.7165\u001b[0m        \u001b[35m0.8137\u001b[0m  42.3950\n",
            "     13        \u001b[36m0.9018\u001b[0m        \u001b[32m0.7154\u001b[0m        \u001b[35m0.8133\u001b[0m  42.2519\n",
            "     14        \u001b[36m0.9013\u001b[0m        \u001b[32m0.7138\u001b[0m        \u001b[35m0.8123\u001b[0m  42.8335\n",
            "     15        0.9015        \u001b[32m0.7129\u001b[0m        0.8127  42.0313\n",
            "     16        \u001b[36m0.9010\u001b[0m        \u001b[32m0.7104\u001b[0m        \u001b[35m0.8119\u001b[0m  42.0670\n",
            "     17        \u001b[36m0.9009\u001b[0m        \u001b[32m0.7101\u001b[0m        \u001b[35m0.8116\u001b[0m  42.2290\n",
            "     18        0.9011        \u001b[32m0.7097\u001b[0m        0.8120  41.8921\n",
            "     19        0.9009        \u001b[32m0.7096\u001b[0m        0.8117  42.5101\n",
            "     20        0.9009        \u001b[32m0.7095\u001b[0m        0.8116  42.2418\n",
            "     21        \u001b[36m0.9008\u001b[0m        \u001b[32m0.7094\u001b[0m        \u001b[35m0.8114\u001b[0m  42.4756\n",
            "     22        0.9008        \u001b[32m0.7093\u001b[0m        0.8115  42.4902\n",
            "     23        0.9008        \u001b[32m0.7088\u001b[0m        0.8115  43.2331\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV]  lr=0.001, module__dropout=0.2, module__size_emb=30, score=-1.045, total=21.3min\n",
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 120.6min remaining:    0.0s\n",
            "[CV] lr=0.001, module__dropout=0.2, module__size_emb=60 ..............\n",
            "  epoch    rmse_score    train_loss    valid_loss      dur\n",
            "-------  ------------  ------------  ------------  -------\n",
            "      1        \u001b[36m0.9291\u001b[0m        \u001b[32m1.0118\u001b[0m        \u001b[35m0.8633\u001b[0m  42.8714\n",
            "      2        \u001b[36m0.9185\u001b[0m        \u001b[32m0.8391\u001b[0m        \u001b[35m0.8437\u001b[0m  42.8123\n",
            "      3        \u001b[36m0.9135\u001b[0m        \u001b[32m0.8189\u001b[0m        \u001b[35m0.8345\u001b[0m  43.4143\n",
            "      4        \u001b[36m0.9074\u001b[0m        \u001b[32m0.8061\u001b[0m        \u001b[35m0.8234\u001b[0m  42.9189\n",
            "      5        \u001b[36m0.9019\u001b[0m        \u001b[32m0.7924\u001b[0m        \u001b[35m0.8134\u001b[0m  43.6360\n",
            "      6        \u001b[36m0.8985\u001b[0m        \u001b[32m0.7793\u001b[0m        \u001b[35m0.8073\u001b[0m  43.4348\n",
            "      7        \u001b[36m0.8932\u001b[0m        \u001b[32m0.7682\u001b[0m        \u001b[35m0.7978\u001b[0m  43.3154\n",
            "      8        \u001b[36m0.8906\u001b[0m        \u001b[32m0.7585\u001b[0m        \u001b[35m0.7932\u001b[0m  43.4914\n",
            "      9        \u001b[36m0.8879\u001b[0m        \u001b[32m0.7338\u001b[0m        \u001b[35m0.7884\u001b[0m  43.1372\n",
            "     10        \u001b[36m0.8867\u001b[0m        \u001b[32m0.7305\u001b[0m        \u001b[35m0.7863\u001b[0m  43.3755\n",
            "     11        \u001b[36m0.8862\u001b[0m        \u001b[32m0.7285\u001b[0m        \u001b[35m0.7853\u001b[0m  43.9177\n",
            "     12        \u001b[36m0.8854\u001b[0m        \u001b[32m0.7260\u001b[0m        \u001b[35m0.7840\u001b[0m  44.0515\n",
            "     13        \u001b[36m0.8849\u001b[0m        \u001b[32m0.7245\u001b[0m        \u001b[35m0.7831\u001b[0m  43.4154\n",
            "     14        \u001b[36m0.8845\u001b[0m        \u001b[32m0.7229\u001b[0m        \u001b[35m0.7824\u001b[0m  43.6512\n",
            "     15        \u001b[36m0.8840\u001b[0m        \u001b[32m0.7216\u001b[0m        \u001b[35m0.7815\u001b[0m  44.1086\n",
            "     16        \u001b[36m0.8839\u001b[0m        \u001b[32m0.7175\u001b[0m        \u001b[35m0.7812\u001b[0m  43.9865\n",
            "     17        \u001b[36m0.8838\u001b[0m        \u001b[32m0.7173\u001b[0m        \u001b[35m0.7810\u001b[0m  43.8045\n",
            "     18        0.8838        0.7175        0.7811  43.9287\n",
            "     19        \u001b[36m0.8837\u001b[0m        \u001b[32m0.7172\u001b[0m        \u001b[35m0.7809\u001b[0m  43.5996\n",
            "     20        \u001b[36m0.8836\u001b[0m        \u001b[32m0.7170\u001b[0m        \u001b[35m0.7808\u001b[0m  43.6383\n",
            "     21        \u001b[36m0.8836\u001b[0m        0.7171        \u001b[35m0.7807\u001b[0m  43.5097\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV]  lr=0.001, module__dropout=0.2, module__size_emb=60, score=-0.936, total=20.0min\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 140.7min remaining:    0.0s\n",
            "[CV] lr=0.001, module__dropout=0.2, module__size_emb=60 ..............\n",
            "  epoch    rmse_score    train_loss    valid_loss      dur\n",
            "-------  ------------  ------------  ------------  -------\n",
            "      1        \u001b[36m0.9278\u001b[0m        \u001b[32m1.0125\u001b[0m        \u001b[35m0.8609\u001b[0m  42.9313\n",
            "      2        \u001b[36m0.9179\u001b[0m        \u001b[32m0.8211\u001b[0m        \u001b[35m0.8426\u001b[0m  43.6083\n",
            "      3        \u001b[36m0.9147\u001b[0m        \u001b[32m0.8013\u001b[0m        \u001b[35m0.8366\u001b[0m  43.5896\n",
            "      4        \u001b[36m0.9085\u001b[0m        \u001b[32m0.7899\u001b[0m        \u001b[35m0.8254\u001b[0m  44.2202\n",
            "      5        \u001b[36m0.9035\u001b[0m        \u001b[32m0.7777\u001b[0m        \u001b[35m0.8164\u001b[0m  43.9256\n",
            "      6        \u001b[36m0.8988\u001b[0m        \u001b[32m0.7648\u001b[0m        \u001b[35m0.8078\u001b[0m  44.4332\n",
            "      7        \u001b[36m0.8951\u001b[0m        \u001b[32m0.7532\u001b[0m        \u001b[35m0.8012\u001b[0m  44.3922\n",
            "      8        \u001b[36m0.8912\u001b[0m        \u001b[32m0.7435\u001b[0m        \u001b[35m0.7942\u001b[0m  44.8411\n",
            "      9        \u001b[36m0.8898\u001b[0m        \u001b[32m0.7200\u001b[0m        \u001b[35m0.7917\u001b[0m  43.7404\n",
            "     10        \u001b[36m0.8891\u001b[0m        \u001b[32m0.7161\u001b[0m        \u001b[35m0.7906\u001b[0m  43.3421\n",
            "     11        \u001b[36m0.8880\u001b[0m        \u001b[32m0.7140\u001b[0m        \u001b[35m0.7886\u001b[0m  44.0116\n",
            "     12        \u001b[36m0.8878\u001b[0m        \u001b[32m0.7120\u001b[0m        \u001b[35m0.7882\u001b[0m  43.8559\n",
            "     13        \u001b[36m0.8874\u001b[0m        \u001b[32m0.7097\u001b[0m        \u001b[35m0.7875\u001b[0m  44.0094\n",
            "     14        \u001b[36m0.8868\u001b[0m        \u001b[32m0.7082\u001b[0m        \u001b[35m0.7864\u001b[0m  43.4804\n",
            "     15        \u001b[36m0.8863\u001b[0m        \u001b[32m0.7071\u001b[0m        \u001b[35m0.7855\u001b[0m  43.4664\n",
            "     16        \u001b[36m0.8862\u001b[0m        \u001b[32m0.7035\u001b[0m        \u001b[35m0.7854\u001b[0m  44.3864\n",
            "     17        \u001b[36m0.8861\u001b[0m        \u001b[32m0.7034\u001b[0m        \u001b[35m0.7852\u001b[0m  43.7279\n",
            "     18        \u001b[36m0.8861\u001b[0m        \u001b[32m0.7030\u001b[0m        \u001b[35m0.7852\u001b[0m  43.7772\n",
            "     19        0.8861        \u001b[32m0.7026\u001b[0m        0.7852  43.3175\n",
            "     20        \u001b[36m0.8859\u001b[0m        \u001b[32m0.7022\u001b[0m        \u001b[35m0.7848\u001b[0m  43.0342\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV]  lr=0.001, module__dropout=0.2, module__size_emb=60, score=-0.980, total=19.1min\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 159.8min remaining:    0.0s\n",
            "[CV] lr=0.001, module__dropout=0.2, module__size_emb=60 ..............\n",
            "  epoch    rmse_score    train_loss    valid_loss      dur\n",
            "-------  ------------  ------------  ------------  -------\n",
            "      1        \u001b[36m0.9342\u001b[0m        \u001b[32m0.9821\u001b[0m        \u001b[35m0.8728\u001b[0m  41.5923\n",
            "      2        \u001b[36m0.9257\u001b[0m        \u001b[32m0.8040\u001b[0m        \u001b[35m0.8568\u001b[0m  42.2280\n",
            "      3        \u001b[36m0.9226\u001b[0m        \u001b[32m0.7859\u001b[0m        \u001b[35m0.8512\u001b[0m  42.5900\n",
            "      4        \u001b[36m0.9161\u001b[0m        \u001b[32m0.7764\u001b[0m        \u001b[35m0.8392\u001b[0m  42.0970\n",
            "      5        \u001b[36m0.9108\u001b[0m        \u001b[32m0.7638\u001b[0m        \u001b[35m0.8295\u001b[0m  42.7718\n",
            "      6        \u001b[36m0.9093\u001b[0m        \u001b[32m0.7513\u001b[0m        \u001b[35m0.8268\u001b[0m  42.6426\n",
            "      7        \u001b[36m0.9045\u001b[0m        \u001b[32m0.7417\u001b[0m        \u001b[35m0.8182\u001b[0m  42.7278\n",
            "      8        \u001b[36m0.9027\u001b[0m        \u001b[32m0.7333\u001b[0m        \u001b[35m0.8149\u001b[0m  42.6800\n",
            "      9        \u001b[36m0.8994\u001b[0m        \u001b[32m0.7120\u001b[0m        \u001b[35m0.8089\u001b[0m  42.6691\n",
            "     10        \u001b[36m0.8985\u001b[0m        \u001b[32m0.7088\u001b[0m        \u001b[35m0.8073\u001b[0m  42.7140\n",
            "     11        \u001b[36m0.8978\u001b[0m        \u001b[32m0.7067\u001b[0m        \u001b[35m0.8061\u001b[0m  43.1817\n",
            "     12        \u001b[36m0.8969\u001b[0m        \u001b[32m0.7051\u001b[0m        \u001b[35m0.8044\u001b[0m  42.9651\n",
            "     13        \u001b[36m0.8964\u001b[0m        \u001b[32m0.7035\u001b[0m        \u001b[35m0.8035\u001b[0m  42.4049\n",
            "     14        \u001b[36m0.8960\u001b[0m        \u001b[32m0.7023\u001b[0m        \u001b[35m0.8028\u001b[0m  43.0727\n",
            "     15        \u001b[36m0.8958\u001b[0m        \u001b[32m0.7007\u001b[0m        \u001b[35m0.8024\u001b[0m  42.6371\n",
            "     16        \u001b[36m0.8958\u001b[0m        \u001b[32m0.6974\u001b[0m        \u001b[35m0.8024\u001b[0m  42.6000\n",
            "     17        \u001b[36m0.8957\u001b[0m        \u001b[32m0.6974\u001b[0m        \u001b[35m0.8023\u001b[0m  42.9370\n",
            "     18        \u001b[36m0.8957\u001b[0m        \u001b[32m0.6969\u001b[0m        \u001b[35m0.8023\u001b[0m  42.2048\n",
            "     19        \u001b[36m0.8956\u001b[0m        0.6969        \u001b[35m0.8021\u001b[0m  42.3577\n",
            "     20        \u001b[36m0.8955\u001b[0m        \u001b[32m0.6967\u001b[0m        \u001b[35m0.8020\u001b[0m  42.3435\n",
            "     21        0.8957        \u001b[32m0.6964\u001b[0m        0.8022  42.2443\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV]  lr=0.001, module__dropout=0.2, module__size_emb=60, score=-1.044, total=19.4min\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 179.2min remaining:    0.0s\n",
            "[CV] lr=0.001, module__dropout=0.2, module__size_emb=120 .............\n",
            "  epoch    rmse_score    train_loss    valid_loss      dur\n",
            "-------  ------------  ------------  ------------  -------\n",
            "      1        \u001b[36m0.9283\u001b[0m        \u001b[32m1.0034\u001b[0m        \u001b[35m0.8617\u001b[0m  43.2628\n",
            "      2        \u001b[36m0.9179\u001b[0m        \u001b[32m0.8380\u001b[0m        \u001b[35m0.8425\u001b[0m  46.2054\n",
            "      3        \u001b[36m0.9144\u001b[0m        \u001b[32m0.8190\u001b[0m        \u001b[35m0.8361\u001b[0m  47.0102\n",
            "      4        \u001b[36m0.9080\u001b[0m        \u001b[32m0.8065\u001b[0m        \u001b[35m0.8245\u001b[0m  46.7201\n",
            "      5        \u001b[36m0.9018\u001b[0m        \u001b[32m0.7929\u001b[0m        \u001b[35m0.8133\u001b[0m  47.1591\n",
            "      6        \u001b[36m0.8974\u001b[0m        \u001b[32m0.7779\u001b[0m        \u001b[35m0.8054\u001b[0m  46.9570\n",
            "      7        \u001b[36m0.8927\u001b[0m        \u001b[32m0.7653\u001b[0m        \u001b[35m0.7970\u001b[0m  46.4224\n",
            "      8        \u001b[36m0.8897\u001b[0m        \u001b[32m0.7558\u001b[0m        \u001b[35m0.7915\u001b[0m  47.2376\n",
            "      9        \u001b[36m0.8866\u001b[0m        \u001b[32m0.7301\u001b[0m        \u001b[35m0.7860\u001b[0m  46.7017\n",
            "     10        \u001b[36m0.8855\u001b[0m        \u001b[32m0.7261\u001b[0m        \u001b[35m0.7840\u001b[0m  47.1861\n",
            "     11        \u001b[36m0.8846\u001b[0m        \u001b[32m0.7236\u001b[0m        \u001b[35m0.7826\u001b[0m  46.8425\n",
            "     12        \u001b[36m0.8839\u001b[0m        \u001b[32m0.7215\u001b[0m        \u001b[35m0.7813\u001b[0m  46.9114\n",
            "     13        \u001b[36m0.8835\u001b[0m        \u001b[32m0.7194\u001b[0m        \u001b[35m0.7806\u001b[0m  46.5870\n",
            "     14        \u001b[36m0.8827\u001b[0m        \u001b[32m0.7176\u001b[0m        \u001b[35m0.7791\u001b[0m  46.8207\n",
            "     15        \u001b[36m0.8821\u001b[0m        \u001b[32m0.7160\u001b[0m        \u001b[35m0.7780\u001b[0m  47.3150\n",
            "     16        \u001b[36m0.8820\u001b[0m        \u001b[32m0.7121\u001b[0m        \u001b[35m0.7779\u001b[0m  46.6517\n",
            "     17        0.8820        \u001b[32m0.7119\u001b[0m        0.7779  46.6193\n",
            "     18        0.8820        \u001b[32m0.7117\u001b[0m        0.7779  46.7242\n",
            "     19        \u001b[36m0.8819\u001b[0m        \u001b[32m0.7116\u001b[0m        \u001b[35m0.7777\u001b[0m  47.3964\n",
            "     20        \u001b[36m0.8818\u001b[0m        \u001b[32m0.7110\u001b[0m        \u001b[35m0.7776\u001b[0m  46.8586\n",
            "     21        \u001b[36m0.8818\u001b[0m        \u001b[32m0.7110\u001b[0m        \u001b[35m0.7775\u001b[0m  46.5623\n",
            "     22        \u001b[36m0.8817\u001b[0m        \u001b[32m0.7109\u001b[0m        \u001b[35m0.7774\u001b[0m  46.9605\n",
            "     23        \u001b[36m0.8817\u001b[0m        \u001b[32m0.7104\u001b[0m        \u001b[35m0.7774\u001b[0m  46.6516\n",
            "     24        \u001b[36m0.8817\u001b[0m        0.7105        \u001b[35m0.7774\u001b[0m  46.4861\n",
            "     25        \u001b[36m0.8817\u001b[0m        \u001b[32m0.7101\u001b[0m        \u001b[35m0.7774\u001b[0m  46.6649\n",
            "     26        \u001b[36m0.8817\u001b[0m        0.7103        \u001b[35m0.7774\u001b[0m  46.8350\n",
            "     27        \u001b[36m0.8817\u001b[0m        0.7105        \u001b[35m0.7773\u001b[0m  46.5614\n",
            "     28        \u001b[36m0.8817\u001b[0m        0.7102        \u001b[35m0.7773\u001b[0m  46.4589\n",
            "     29        \u001b[36m0.8817\u001b[0m        0.7105        \u001b[35m0.7773\u001b[0m  46.6696\n",
            "     30        \u001b[36m0.8817\u001b[0m        0.7102        \u001b[35m0.7773\u001b[0m  46.8893\n",
            "[CV]  lr=0.001, module__dropout=0.2, module__size_emb=120, score=-0.940, total=28.5min\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 207.8min remaining:    0.0s\n",
            "[CV] lr=0.001, module__dropout=0.2, module__size_emb=120 .............\n",
            "  epoch    rmse_score    train_loss    valid_loss      dur\n",
            "-------  ------------  ------------  ------------  -------\n",
            "      1        \u001b[36m0.9257\u001b[0m        \u001b[32m0.9836\u001b[0m        \u001b[35m0.8569\u001b[0m  44.6259\n",
            "      2        \u001b[36m0.9160\u001b[0m        \u001b[32m0.8167\u001b[0m        \u001b[35m0.8391\u001b[0m  45.3526\n",
            "      3        \u001b[36m0.9114\u001b[0m        \u001b[32m0.7976\u001b[0m        \u001b[35m0.8306\u001b[0m  45.0245\n",
            "      4        \u001b[36m0.9058\u001b[0m        \u001b[32m0.7847\u001b[0m        \u001b[35m0.8204\u001b[0m  46.6314\n",
            "      5        \u001b[36m0.9002\u001b[0m        \u001b[32m0.7715\u001b[0m        \u001b[35m0.8104\u001b[0m  46.8532\n",
            "      6        \u001b[36m0.8958\u001b[0m        \u001b[32m0.7578\u001b[0m        \u001b[35m0.8025\u001b[0m  46.7343\n",
            "      7        \u001b[36m0.8935\u001b[0m        \u001b[32m0.7469\u001b[0m        \u001b[35m0.7983\u001b[0m  46.9000\n",
            "      8        \u001b[36m0.8906\u001b[0m        \u001b[32m0.7385\u001b[0m        \u001b[35m0.7931\u001b[0m  47.2592\n",
            "      9        \u001b[36m0.8882\u001b[0m        \u001b[32m0.7139\u001b[0m        \u001b[35m0.7890\u001b[0m  47.4896\n",
            "     10        \u001b[36m0.8869\u001b[0m        \u001b[32m0.7103\u001b[0m        \u001b[35m0.7866\u001b[0m  46.9417\n",
            "     11        \u001b[36m0.8855\u001b[0m        \u001b[32m0.7077\u001b[0m        \u001b[35m0.7841\u001b[0m  47.3553\n",
            "     12        \u001b[36m0.8849\u001b[0m        \u001b[32m0.7056\u001b[0m        \u001b[35m0.7830\u001b[0m  47.4218\n",
            "     13        \u001b[36m0.8847\u001b[0m        \u001b[32m0.7038\u001b[0m        \u001b[35m0.7826\u001b[0m  47.0307\n",
            "     14        \u001b[36m0.8839\u001b[0m        \u001b[32m0.7021\u001b[0m        \u001b[35m0.7813\u001b[0m  47.3913\n",
            "     15        \u001b[36m0.8832\u001b[0m        \u001b[32m0.7004\u001b[0m        \u001b[35m0.7800\u001b[0m  47.6128\n",
            "     16        0.8832        \u001b[32m0.6963\u001b[0m        0.7800  46.9858\n",
            "     17        \u001b[36m0.8831\u001b[0m        \u001b[32m0.6959\u001b[0m        \u001b[35m0.7799\u001b[0m  47.4634\n",
            "     18        0.8831        0.6959        0.7799  46.8915\n",
            "     19        \u001b[36m0.8830\u001b[0m        \u001b[32m0.6956\u001b[0m        \u001b[35m0.7796\u001b[0m  46.9541\n",
            "     20        0.8830        \u001b[32m0.6954\u001b[0m        0.7797  46.8911\n",
            "     21        \u001b[36m0.8829\u001b[0m        0.6957        \u001b[35m0.7796\u001b[0m  46.5077\n",
            "     22        \u001b[36m0.8828\u001b[0m        \u001b[32m0.6949\u001b[0m        \u001b[35m0.7794\u001b[0m  47.4598\n",
            "     23        \u001b[36m0.8828\u001b[0m        \u001b[32m0.6948\u001b[0m        \u001b[35m0.7794\u001b[0m  47.2096\n",
            "     24        \u001b[36m0.8828\u001b[0m        \u001b[32m0.6945\u001b[0m        \u001b[35m0.7794\u001b[0m  46.8378\n",
            "Stopping since valid_loss has not improved in the last 10 epochs.\n",
            "[CV]  lr=0.001, module__dropout=0.2, module__size_emb=120, score=-0.978, total=23.8min\n",
            "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed: 231.7min remaining:    0.0s\n",
            "[CV] lr=0.001, module__dropout=0.2, module__size_emb=120 .............\n",
            "  epoch    rmse_score    train_loss    valid_loss      dur\n",
            "-------  ------------  ------------  ------------  -------\n",
            "      1        \u001b[36m0.9340\u001b[0m        \u001b[32m0.9551\u001b[0m        \u001b[35m0.8723\u001b[0m  49.1478\n",
            "      2        \u001b[36m0.9232\u001b[0m        \u001b[32m0.8017\u001b[0m        \u001b[35m0.8523\u001b[0m  49.1872\n",
            "      3        \u001b[36m0.9195\u001b[0m        \u001b[32m0.7839\u001b[0m        \u001b[35m0.8455\u001b[0m  49.1408\n",
            "      4        \u001b[36m0.9129\u001b[0m        \u001b[32m0.7699\u001b[0m        \u001b[35m0.8334\u001b[0m  49.0492\n",
            "      5        \u001b[36m0.9091\u001b[0m        \u001b[32m0.7566\u001b[0m        \u001b[35m0.8265\u001b[0m  49.4445\n",
            "      6        \u001b[36m0.9063\u001b[0m        \u001b[32m0.7450\u001b[0m        \u001b[35m0.8213\u001b[0m  49.3998\n",
            "      7        \u001b[36m0.9020\u001b[0m        \u001b[32m0.7370\u001b[0m        \u001b[35m0.8137\u001b[0m  50.1491\n",
            "      8        \u001b[36m0.8987\u001b[0m        \u001b[32m0.7298\u001b[0m        \u001b[35m0.8077\u001b[0m  49.8488\n",
            "      9        \u001b[36m0.8985\u001b[0m        \u001b[32m0.7094\u001b[0m        \u001b[35m0.8074\u001b[0m  50.2211\n",
            "     10        \u001b[36m0.8985\u001b[0m        \u001b[32m0.7059\u001b[0m        \u001b[35m0.8074\u001b[0m  50.0428\n",
            "     11        \u001b[36m0.8970\u001b[0m        \u001b[32m0.7039\u001b[0m        \u001b[35m0.8046\u001b[0m  50.4016\n",
            "     12        0.8970        \u001b[32m0.7022\u001b[0m        0.8047  50.2918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_9-m9v_3q03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twoembedsnet = NeuralNet(\n",
        "    twoembeds,\n",
        "    module__size_emb=128,\n",
        "    max_epochs=30,\n",
        "    lr=0.001,\n",
        "    optimizer=torch.optim.Adam,\n",
        "    criterion=torch.nn.MSELoss,\n",
        "    device=device,\n",
        "    iterator_train__batch_size=4096,\n",
        "    iterator_train__num_workers=4,\n",
        "    iterator_train__shuffle=True,\n",
        "    iterator_valid__batch_size=4096,\n",
        "    train_split=predefined_split(valid_dataset),\n",
        "    callbacks=[earlystopping,\n",
        "               epoch_rmse,\n",
        "               #checkpoint,\n",
        "               lr_scheduler]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9B_Z4LA6CPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twoembedsnet.fit(train_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2QlpxyRTx7b",
        "colab_type": "code",
        "outputId": "35483166-0d89-4148-c625-50c8884a9903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "params = {\n",
        "    #'lr': [0.001, 0.01],\n",
        "    'module__size_emb': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "}\n",
        "gs = GridSearchCV(twoembedsnet, params, refit=False, n_jobs=2, cv=2, scoring='neg_mean_squared_error')\n",
        "\n",
        "X_ds = SliceDataset(train, idx=0)\n",
        "y_ds = SliceDataset(train, idx=1)\n",
        "gs.fit(X_ds, y_ds)\n",
        "\n",
        "print(gs.best_score_, gs.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-4182ed88c699>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    853\u001b[0m                     \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \"\"\"Shutdown the workers and restart a new one with the same parameters\n\u001b[1;32m    537\u001b[0m         \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0mdelete_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_temp_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, kill_workers)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m                 \u001b[0mqmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0mcq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7FhrD3V6ZHC",
        "colab_type": "code",
        "outputId": "7c3f91e6-fbf7-4c76-9dc2-508ba4e91325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "### Helper function to time the speed of the dataset in a dataloader\n",
        "for i in torch.utils.data.DataLoader(train_dataset, batch_size=4096, num_workers=4, shuffle=False):\n",
        "    #a, b = i\n",
        "    a = i\n",
        "    #for j in a:\n",
        "        #print(j.type())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fef7a5fd9e8>>\n",
            "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fef7a5fd9e8>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
            "    self._shutdown_workers()\n",
            "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fef7a5fd9e8>>\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "Traceback (most recent call last):\n",
            "AssertionError: can only join a child process\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
            "    w.join()\n",
            "AssertionError: can only join a child process\n",
            "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fef7a5fd9e8>>\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n",
            "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
            "AssertionError: can only join a child process\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 883 ms, sys: 354 ms, total: 1.24 s\n",
            "Wall time: 26.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFcj5YcEeuO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "current_time = str(datetime.datetime.now().timestamp())\n",
        "train_log_dir = '/content/drive2/My Drive/tb/logs/tensorboard/train/' + current_time\n",
        "valid_log_dir = '/content/drive2/My Drive/tb/logs/tensorboard/valid/' + current_time\n",
        "train_summary_writer = summary.create_file_writer(train_log_dir)\n",
        "valid_summary_writer = summary.create_file_writer(valid_log_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6QaTiHtHtrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=50):\n",
        "    since = time.time()\n",
        "    \n",
        "    globaliter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "        \n",
        "        globaliter +=1\n",
        "\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train(True)\n",
        "            else:\n",
        "                model.train(False)\n",
        "            \n",
        "            running_loss = 0.0\n",
        "\n",
        "            #for users_emb, users_ohe, movies_emb, movies_ohe, interact, labels in dataloaders[phase]:\n",
        "            for X, labels in dataloaders[phase]:\n",
        "   \n",
        "                #users_emb, users_ohe, movies_emb, movies_ohe, interact, labels = (Variable(users_emb.to(device)),\n",
        "                #                                                              Variable(users_ohe.to(device)), \n",
        "                #                                                                  Variable(movies_emb.to(device)),\n",
        "                #                                                                  Variable(movies_ohe.to(device)),\n",
        "                #                                                                  Variable(interact.to(device)),\n",
        "                #                                                                  Variable(labels.to(device)).float())\n",
        "                \n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                outputs = model(X)\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()    \n",
        "                \n",
        "                #print(model.emb_UserID.weight.grad)\n",
        "\n",
        "                running_loss += loss.data\n",
        "            \n",
        "            epoch_loss = running_loss / (len(dataloaders[phase].dataset))\n",
        "            sqrt_loss = torch.sqrt(epoch_loss)\n",
        "            \n",
        "            # Tensorboard logging\n",
        "            if phase == 'train':\n",
        "                with train_summary_writer.as_default():\n",
        "                    tf.summary.scalar(model.name + ' RMSE', sqrt_loss.item(), step=globaliter)\n",
        "            else:\n",
        "                with valid_summary_writer.as_default():\n",
        "                    tf.summary.scalar(model.name + ' RMSE', sqrt_loss.item(), step=globaliter)\n",
        "            \n",
        "            print('{} loss: MSE: {:.6f} RMSE: {:.6f}'.format(phase, epoch_loss, sqrt_loss))\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print(time_elapsed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1nLS_9iytG-o",
        "outputId": "d5149ac5-67a9-45ec-abe6-5f30469dc317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "criterion = nn.MSELoss(reduction='sum') # we use sum because in the training loop, we divide by the length of the dataset\n",
        "#optimizer_ft = optim.SGD(model.parameters(), lr=0.001, weight_decay=1e-5)#, momentum=0.9, weight_decay=1e-5)\n",
        "optimizer_ft = optim.Adam(model.parameters(), lr=0.001)\n",
        "#optimizer_ft = RAdam(model.parameters())\n",
        "train_model(model, criterion, optimizer_ft, None, 50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/49\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-159-4cbe5d84b8a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#optimizer_ft = RAdam(model.parameters())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-158-b3e12c7ad84d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-149-039fcc6f805f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mMovieID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovie_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#print(MovieID.max(), train.movies)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0muser_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_UserID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUserID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mmovie_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_MovieID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMovieID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m         return F.embedding(\n\u001b[1;32m    116\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1506\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CUDA but got backend CPU for argument #3 'index'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EYIwzIagqnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir '/content/drive2/My Drive/tb/logs/tensorboard'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_WP8cIqZQWN",
        "colab_type": "text"
      },
      "source": [
        "### Surprise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pjhfBV6ZRUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install surprise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsJ69IyMZTcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from surprise import NormalPredictor\n",
        "from surprise import SVD\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import cross_validate, train_test_split, KFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG7J_vXTZjcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user = train[dataloaders['train'].dataset.indices][0][:, 0].data.numpy()\n",
        "movie = train[dataloaders['train'].dataset.indices][2][:, 0].data.numpy()\n",
        "y = train[dataloaders['train'].dataset.indices][5].data.numpy()\n",
        "df = pd.DataFrame({'user': user, 'movie': movie, 'y': y})\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(df[['user', 'movie', 'y']], reader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khqq2oRQwyZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = Dataset.load_from_df(train.ratings.loc[dataloaders['train'].dataset.indices, ['UserID', 'MovieID', 'Rating']], reader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZULF4SZexU81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = train.ratings.loc[dataloaders['train'].dataset.indices, ['UserID', 'MovieID', 'Rating']]\n",
        "b = pd.DataFrame({'UserID': user, 'MovieID': movie, 'Rating': y})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osa_K_dkckBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data = Dataset.load_builtin('ml-1m')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePIcLN-Vawop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample random trainset and testset\n",
        "# test set is made of 25% of the ratings.\n",
        "trainset, testset = train_test_split(data, test_size=.25)\n",
        "\n",
        "# We'll use the famous SVD algorithm.\n",
        "algo = SVD()\n",
        "\n",
        "# Train the algorithm on the trainset, and predict ratings for the testset\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Then compute RMSE\n",
        "accuracy.rmse(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHY401zJgx8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}